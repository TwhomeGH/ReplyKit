//
//  Untitled.swift
//  liveAPP
//
//  Created by user on 2025/10/24.
//

import UIKit
import CoreMedia
import VideoToolbox
import Accelerate

// MARK: æš«åœä¸­
// å»ºç«‹ PixelBuffer
// MARK: - å·¥å…·
/// å»ºç«‹æˆ–é‡ç”¨ä¸€å€‹æŒ‡å®šæ ¼å¼çš„ CVPixelBufferã€‚
///
/// - Parameters:
///   - width: å¯¬åº¦ï¼ˆåƒç´ ï¼‰
///   - height: é«˜åº¦ï¼ˆåƒç´ ï¼‰
///   - format: Pixel æ ¼å¼ï¼ˆä¾‹å¦‚ kCVPixelFormatType_32BGRA / kCVPixelFormatType_420YpCbCr8BiPlanarFullRangeï¼‰
///   - reuse: å¯é¸ï¼Œå‚³å…¥èˆŠçš„ buffer ç”¨æ–¼é‡ç”¨ï¼ˆè‹¥å°ºå¯¸èˆ‡æ ¼å¼ç›¸åŒï¼‰
/// - Returns: å¯ç”¨çš„ CVPixelBufferï¼ˆæ–°å»ºæˆ–é‡ç”¨ï¼‰
func createPixelBuffer(width: Int, height: Int, format: OSType, reuse existing: CVPixelBuffer?) -> CVPixelBuffer? {
    // âœ… è‹¥å·²æœ‰å¯é‡ç”¨ buffer ä¸”å°ºå¯¸ã€æ ¼å¼ä¸€è‡´ï¼Œç›´æ¥å›å‚³
    if let existing = existing,
       CVPixelBufferGetWidth(existing) == width,
       CVPixelBufferGetHeight(existing) == height,
       CVPixelBufferGetPixelFormatType(existing) == format {
        sendlog(message: "â™»ï¸ Reuse PixelBuffer (\(width)x\(height), format: \(format))")
        
        return existing
    }

    // âœ… å¦å‰‡é‡æ–°å»ºç«‹
    var buffer: CVPixelBuffer?
    let attrs = [
        kCVPixelBufferIOSurfacePropertiesKey: [:] as CFDictionary,
        kCVPixelBufferCGImageCompatibilityKey: true,
        kCVPixelBufferCGBitmapContextCompatibilityKey: true
    ] as CFDictionary

    let status = CVPixelBufferCreate(
        kCFAllocatorDefault,
        width,
        height,
        format,
        attrs,
        &buffer
    )

    if status == kCVReturnSuccess, let buffer = buffer {
            sendlog(message: "ğŸ†• Created new PixelBuffer (\(width)x\(height), format: \(format))")
            return buffer
        } else {
            sendlog(message: "âŒ Failed to create PixelBuffer (status: \(status))")
            return nil
        }

}

// MARK: - å»ºç«‹ CGContext
func createContext(for pixelBuffer: CVPixelBuffer) -> CGContext? {
    let flags = CVPixelBufferLockFlags(rawValue: 0)
    guard kCVReturnSuccess == CVPixelBufferLockBaseAddress(pixelBuffer, flags),
          let baseAddress = CVPixelBufferGetBaseAddress(pixelBuffer) else {
        sendlog(message: "âŒ createContext: ç„¡æ³• lock æˆ– baseAddress ç‚º nil")
        return nil
    }

    let width = CVPixelBufferGetWidth(pixelBuffer)
    let height = CVPixelBufferGetHeight(pixelBuffer)
    let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)

    let context = CGContext(data: baseAddress,
                            width: width,
                            height: height,
                            bitsPerComponent: 8,
                            bytesPerRow: bytesPerRow,
                            space: CGColorSpaceCreateDeviceRGB(),
                            bitmapInfo: CGImageAlphaInfo.premultipliedFirst.rawValue)
    return context
}


// MARK: - æ›´æ–°æš«åœç•«é¢
func updatePausedContext(buffer: CVPixelBuffer, context: CGContext, text: String) {
    let flags = CVPixelBufferLockFlags(rawValue: 0)
    guard kCVReturnSuccess == CVPixelBufferLockBaseAddress(buffer, flags) else {
        sendlog(message: "âŒ updatePausedContext: ç„¡æ³• lock buffer")
        return
    }
    defer { CVPixelBufferUnlockBaseAddress(buffer, flags) }

    let width = CVPixelBufferGetWidth(buffer)
    let height = CVPixelBufferGetHeight(buffer)

    // é˜²å‘†
    guard context.width == width, context.height == height else {
        sendlog(message: "âš ï¸ updatePausedContext: context å°ºå¯¸èˆ‡ buffer ä¸ç¬¦")
        return
    }

    // é»‘åº•
    context.setFillColor(UIColor.black.cgColor)
    context.fill(CGRect(x: 0, y: 0, width: width, height: height))

    // æ–‡å­—
    let paragraph = NSMutableParagraphStyle()
    paragraph.alignment = .center
    let attrs: [NSAttributedString.Key: Any] = [
        .font: UIFont.boldSystemFont(ofSize: CGFloat(height) * 0.08),
        .foregroundColor: UIColor.white,
        .paragraphStyle: paragraph
    ]
    let textRect = CGRect(x: 0, y: (height-50)/2, width: width, height: 50)
    NSString(string: text).draw(in: textRect, withAttributes: attrs)
}


// MARK: - BGRA -> NV12
func convertBGRAtoNV12(bgra: CVPixelBuffer, nv12: CVPixelBuffer) {
    CVPixelBufferLockBaseAddress(bgra, .readOnly)
    CVPixelBufferLockBaseAddress(nv12, [])
    defer {
        CVPixelBufferUnlockBaseAddress(bgra, .readOnly)
        CVPixelBufferUnlockBaseAddress(nv12, [])
    }

    var sourceBuffer = vImage_Buffer(data: CVPixelBufferGetBaseAddress(bgra),
                                     height: vImagePixelCount(CVPixelBufferGetHeight(bgra)),
                                     width: vImagePixelCount(CVPixelBufferGetWidth(bgra)),
                                     rowBytes: CVPixelBufferGetBytesPerRow(bgra))

    var destY = vImage_Buffer(data: CVPixelBufferGetBaseAddressOfPlane(nv12, 0),
                              height: vImagePixelCount(CVPixelBufferGetHeight(nv12)),
                              width: vImagePixelCount(CVPixelBufferGetWidth(nv12)),
                              rowBytes: CVPixelBufferGetBytesPerRowOfPlane(nv12, 0))

    var destUV = vImage_Buffer(data: CVPixelBufferGetBaseAddressOfPlane(nv12, 1),
                               height: vImagePixelCount(CVPixelBufferGetHeight(nv12)/2),
                               width: vImagePixelCount(CVPixelBufferGetWidth(nv12)/2),
                               rowBytes: CVPixelBufferGetBytesPerRowOfPlane(nv12, 1))

    // å»ºç«‹é»˜èª BT.601 è‰²å½©çŸ©é™£
    var matrix = vImage_ARGBToYpCbCr()
    // å»ºç«‹ pixel range (full 0~255)
    var pixelRange = vImage_YpCbCrPixelRange(Yp_bias: 16, CbCr_bias: 128, YpRangeMax: 235, CbCrRangeMax: 240, YpMax: 235, YpMin: 16, CbCrMax: 240, CbCrMin: 16)


    vImageConvert_ARGB8888To420Yp8_CbCr8(
        &sourceBuffer,
        &destY,
        &destUV,
        &matrix,
        &pixelRange,
        vImage_Flags(kvImageNoFlags)
    )
}

// MARK: - SampleBuffer
// ä¿®æ”¹å¾Œï¼šé€éåƒæ•¸å‚³å…¥ frameIndexï¼Œè¿”å›æ–°çš„ frameIndex
func createSampleBuffer(
    from pixelBuffer: CVPixelBuffer,
    frameIndex: inout Int,
    timescale: CMTimeScale = 30
) -> CMSampleBuffer? {
    var newSampleBuffer: CMSampleBuffer?
    var videoInfo: CMVideoFormatDescription?

    // å»ºç«‹æ ¼å¼æè¿°
    let status = CMVideoFormatDescriptionCreateForImageBuffer(
        allocator: kCFAllocatorDefault,
        imageBuffer: pixelBuffer,
        formatDescriptionOut: &videoInfo
    )
    guard status == noErr, let formatDesc = videoInfo else {
        sendlog(message: "âŒ createSampleBuffer: formatDesc ç”Ÿæˆå¤±æ•— (\(status))")
        return nil
    }

    // å›ºå®š FPS
    let frameDuration = CMTime(value: 1, timescale: timescale)

    // ä½¿ç”¨éå¢çš„ PTSï¼Œç¢ºä¿æ™‚é–“é€£çºŒ
    let pts = CMTime(value: CMTimeValue(frameIndex), timescale: timescale)
    frameIndex += 1

    var timing = CMSampleTimingInfo(
        duration: frameDuration,
        presentationTimeStamp: pts,
        decodeTimeStamp: .invalid
    )

    let sampleStatus = CMSampleBufferCreateForImageBuffer(
        allocator: kCFAllocatorDefault,
        imageBuffer: pixelBuffer,
        dataReady: true,
        makeDataReadyCallback: nil,
        refcon: nil,
        formatDescription: formatDesc,
        sampleTiming: &timing,
        sampleBufferOut: &newSampleBuffer
    )

    guard sampleStatus == noErr else {
        sendlog(message: "âŒ createSampleBuffer: CMSampleBuffer å»ºç«‹å¤±æ•— (\(sampleStatus))")
        return nil
    }

    return newSampleBuffer
}
